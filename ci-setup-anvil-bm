#!/bin/sh

set -e

# some of those are dups but required to deploy a BM from scratch
yum install -y fence-agents-common resource-agents fedpkg mock wget rpm-build createrepo_c yum-utils

BUILDDIR=/root

cd $BUILDDIR

# build update qemu-kvm from fedora (required for Simengine bmc support)
rm -rf $BUILDDIR/qemu-local-build
mkdir -p $BUILDDIR/qemu-local-build

cd qemu-local-build
createrepo .
yum-config-manager --add-repo file:///$(pwd)
echo "module_hotfixes=1" >> /etc/yum.repos.d/root_qemu-local-build.repo
echo "gpgcheck=0" >> /etc/yum.repos.d/root_qemu-local-build.repo
cd ..

rm -rf edk2 rpmbuild
fedpkg co --anonymous edk2
cd edk2
fedpkg srpm
mock -r /etc/mock/centos-stream-8-x86_64.cfg --rebuild *.src.rpm --resultdir=$BUILDDIR/qemu-local-build
rm -rf $BUILDDIR/qemu-local-build/*debuginfo*
cd ..
rm -rf edk2 rpmbuild

rm -rf ipxe rpmbuild
fedpkg co --anonymous ipxe
cd ipxe
fedpkg srpm
mock -r /etc/mock/centos-stream-8-x86_64.cfg --install $BUILDDIR/qemu-local-build/edk2-tools*x86*
mock -r /etc/mock/centos-stream-8-x86_64.cfg --rebuild *.src.rpm --resultdir=$BUILDDIR/qemu-local-build --no-clean
rm -rf $BUILDDIR/qemu-local-build/*debuginfo*
cd ..
rm -rf ipxe rpmbuild

rm -rf qemu rpmbuild
fedpkg co --anonymous qemu
cd qemu
fedpkg switch-branch f35
sed -i -e 's#%dnl.*##g' -e 's#Epoch:.*#Epoch: 20#g' -e 's#,jack,#,#g' -e 's#capstone=system#capstone=auto#g' qemu.spec
fedpkg srpm
mock -r /etc/mock/centos-stream-8-x86_64.cfg --rebuild *.src.rpm --resultdir=$BUILDDIR/qemu-local-build
rm -rf $BUILDDIR/qemu-local-build/*debuginfo*
cd ..
rm -rf qemu rpmbuild

cd qemu-local-build
rm -rf *debuginfo*
createrepo .
cd ..

yum install -y qemu-img qemu-kvm libvirt virt-install lftp httpd fence-virtd-libvirt fence-virtd-tcp postgresql ansible

# build cloud-utils, not available on Centos 8
rm -rf cloud-utils rpmbuild
fedpkg co --anonymous cloud-utils
cd cloud-utils
fedpkg prep
rpmbuild --define "_rpmdir $(pwd)" --define "_srcrpmdir $(pwd)" --define "_sourcedir $(pwd)"  -bb cloud-utils.spec
yum install -y x86_64/*.rpm
cd ..
rm -rf cloud-utils rpmbuild

## setup simengine
# setup Neo4j repo
rpm --import https://debian.neo4j.com/neotechnology.gpg.key
cat <<EOF>  /etc/yum.repos.d/neo4j.repo
[neo4j]
name=Neo4j Yum Repo
baseurl=http://yum.neo4j.com/stable
enabled=1
gpgcheck=1
EOF
neover=$(yum search --showduplicates neo4j |grep neo4j-3 | sed -e 's#neo4j-##g' -e 's#-1.noarch.*##g' | sort -V | tail -n 1)
yum install -y neo4j-$neover
systemctl stop neo4j
systemctl enable neo4j
systemctl start neo4j

dnf -y module remove --all nodejs:10
dnf -y module reset nodejs
dnf -y module switch-to nodejs:12

# build Simengine - model is created after libvirt is configured
rm -rf simengine rpmbuild
git clone https://github.com/Seneca-CDOT/simengine.git
cd simengine/rpm/specfiles
./buildall
cd -
rm -f $BUILDDIR/storcli64
cp simengine/storage-emulation-tests/guest/storcli64 $BUILDDIR/
sed -i -e 's#env python#python3#g' $BUILDDIR/storcli64
yum install -y rpmbuild/RPMS/*/*.rpm
rm -rf simengine rpmbuild

systemctl enable simengine-core

## VIRT SETUP

# enable nested virt
if [ ! -f /etc/modprobe.d/netsted_virt.conf ] && [ "$(cat /sys/module/kvm_intel/parameters/nested)" = 0 ]; then
 systemctl stop libvirtd
 rmmod kvm-intel
 echo 'options kvm-intel nested=y' > /etc/modprobe.d/netsted_virt.conf
 modprobe kvm-intel
fi
if [ "$(cat /sys/module/kvm_intel/parameters/nested)" = 0 ]; then
 echo "WARNING!!! FAILED TO ENABLE NESTED VIRTUALIZATION!"
fi

# setup networking
systemctl start libvirtd
systemctl enable libvirtd
if [ -n "$(virsh net-list --all --name | grep default)" ]; then
 virsh net-destroy default
 virsh net-undefine default
fi

tmpfile=$(mktemp)
macbase=0
ifnbase=122
for i in ifn1 ifn2 bcn1 bcn2 sn1 sn2; do
 if [ -z "$(virsh net-list --all --name | grep ${i}_bridge1)" ]; then
  echo "Creating libvirt network interface ${i}_bridge1"
  uuid=$(uuidgen)
  cat > $tmpfile << EOF
<network>
 <name>${i}_bridge1</name>
 <uuid>${uuid}</uuid>
 <bridge name='${i}_bridge1' stp='on' delay='0'/>
 <domain name='${i}_bridge1'/>
 <mac address='52:54:${macbase}:e1:ac:a2'/>
EOF
  case ${i} in
   ifn*)
    cat >> $tmpfile << EOF
 <forward mode='nat'/>
 <ip address='192.168.$ifnbase.1' netmask='255.255.255.0'>
  <dhcp>
   <range start='192.168.$ifnbase.128' end='192.168.$ifnbase.254'/>
  </dhcp>
 </ip>
EOF
   ;;
   bcn1)
    cat >> $tmpfile << EOF
 <ip address='10.201.2.1' netmask='255.255.0.0'/>
 <ip address='10.201.2.2' netmask='255.255.0.0'/>
 <ip address='10.201.3.1' netmask='255.255.0.0'/>
 <ip address='10.201.3.2' netmask='255.255.0.0'/>
 <ip address='10.201.3.3' netmask='255.255.0.0'/>
 <ip address='10.201.11.1' netmask='255.255.0.0'/>
 <ip address='10.201.11.2' netmask='255.255.0.0'/>
 <ip address='10.201.11.3' netmask='255.255.0.0'/>
EOF
   ;;
  esac
  echo "</network>" >> $tmpfile
  virsh net-define $tmpfile
  virsh net-autostart ${i}_bridge1
  virsh net-start ${i}_bridge1
 fi
 macbase=$((macbase + 1))
 ifnbase=$((ifnbase + 100))
done
rm -f $tmpfile

for i in public libvirt; do
 for x in http https; do
  firewall-cmd --zone=$i --add-service=$x
  firewall-cmd --zone=$i --permanent --add-service=$x
 done
done
firewall-cmd --zone=libvirt --add-port=1229/tcp
firewall-cmd --zone=libvirt --permanent --add-port=1229/tcp
# required by simengine dashboard websocket
firewall-cmd --zone=public --add-port=8000/tcp
firewall-cmd --zone=public --permanent --add-port=8000/tcp
# required by simengine to access UPS/PDU and BMCs
firewall-cmd --zone=libvirt --add-port=161/udp
firewall-cmd --zone=libvirt --permanent --add-port=161/udp
firewall-cmd --zone=libvirt --add-port=623/udp
firewall-cmd --zone=libvirt --permanent --add-port=623/udp
firewall-cmd --reload

systemctl enable httpd
systemctl stop httpd
systemctl start httpd

if ! grep -q ifn1 /etc/fence_virt.conf; then
 sed -i \
  -e 's#virbr0#ifn1_bridge1#g' \
  -e 's#multicast#tcp#g' \
  -e 's#225.0.0.12#192.168.122.1#g' \
  /etc/fence_virt.conf
fi

if [ ! -f /etc/cluster/fence_xvm.key ]; then
 mkdir -p /etc/cluster/
 dd if=/dev/zero of=/etc/cluster/fence_xvm.key bs=4096 count=1
fi

systemctl start fence_virtd
systemctl enable fence_virtd
