#!/bin/sh

set -e

# some of those are dups but required to deploy a BM from scratch
yum install -y fence-agents-common resource-agents mock wget rpm-build createrepo_c yum-utils

BUILDDIR=/root
localmirror=$BUILDDIR/fedmirror

cd $BUILDDIR

# build update qemu-kvm from fedora (required for Simengine bmc support)
rm -rf $BUILDDIR/qemu-local-build
mkdir -p $BUILDDIR/qemu-local-build

cd qemu-local-build
createrepo .
yum-config-manager --add-repo file:///$(pwd)
echo "module_hotfixes=1" >> /etc/yum.repos.d/root_qemu-local-build.repo
echo "gpgcheck=0" >> /etc/yum.repos.d/root_qemu-local-build.repo
cd ..

srpms="edk2 ipxe qemu cloud-utils"
echo "Downloading $srpms"
rm -rf $localmirror
mkdir -p $localmirror
cd $localmirror

cat > $localmirror/fedora-src.repo << EOF
[anvil-fedora-source]
name=Fedora \$releasever - Source
metalink=https://mirrors.fedoraproject.org/metalink?repo=fedora-source-\$releasever&arch=\$basearch
enabled=1
repo_gpgcheck=0
type=rpm
gpgcheck=0
skip_if_unavailable=False

[anvil-updates-source]
name=Fedora \$releasever - Updates Source
metalink=https://mirrors.fedoraproject.org/metalink?repo=updates-released-source-f\$releasever&arch=\$basearch
enabled=1
repo_gpgcheck=0
type=rpm
gpgcheck=0
skip_if_unavailable=False

[anvil-fedora-modular-source]
name=Fedora Modular \$releasever - Source
metalink=https://mirrors.fedoraproject.org/metalink?repo=fedora-modular-source-\$releasever&arch=\$basearch
enabled=1
repo_gpgcheck=0
type=rpm
gpgcheck=0
skip_if_unavailable=False

[anvil-updates-modular-source]
name=Fedora Modular \$releasever - Updates Source
metalink=https://mirrors.fedoraproject.org/metalink?repo=updates-released-modular-source-f\$releasever&arch=\$basearch
enabled=1
repo_gpgcheck=0
type=rpm
gpgcheck=0
skip_if_unavailable=False
EOF

dnf download --source \
	--config $localmirror/fedora-src.repo \
	--releasever 35 \
	--disablerepo="*" \
	--enablerepo=anvil-fedora-source --enablerepo=anvil-updates-source \
	--enablerepo=anvil-fedora-modular-source --enablerepo=anvil-updates-modular-source \
	--installroot=$localmirror/installroot \
	$srpms

cd $BUILDDIR

mock -r /etc/mock/centos-stream-8-x86_64.cfg --rebuild $localmirror/edk2*.src.rpm --resultdir=$BUILDDIR/qemu-local-build
rm -rf $BUILDDIR/qemu-local-build/*debuginfo*
mock -r /etc/mock/centos-stream-8-x86_64.cfg --install $BUILDDIR/qemu-local-build/edk2-tools*x86*
mock -r /etc/mock/centos-stream-8-x86_64.cfg --rebuild $localmirror/ipxe*.src.rpm --resultdir=$BUILDDIR/qemu-local-build --no-clean
rm -rf $BUILDDIR/qemu-local-build/*debuginfo*
mock -r /etc/mock/centos-stream-8-x86_64.cfg --rebuild $localmirror/cloud-utils*.src.rpm --resultdir=$BUILDDIR/qemu-local-build
rm -rf $BUILDDIR/qemu-local-build/*debuginfo*

rm -rf $HOME/rpmbuild
rpm -i $localmirror/qemu*
sed -i -e 's#%dnl.*##g' -e 's#Epoch:.*#Epoch: 20#g' -e 's#,jack,#,#g' -e 's#capstone=system#capstone=auto#g' $HOME/rpmbuild/SPECS/qemu.spec
rpmbuild -bs $HOME/rpmbuild/SPECS/qemu.spec
mock -r /etc/mock/centos-stream-8-x86_64.cfg --rebuild $HOME/rpmbuild/SRPMS/qemu*.src.rpm --resultdir=$BUILDDIR/qemu-local-build
rm -rf $BUILDDIR/qemu-local-build/*debuginfo*

rm -rf $HOME/rpmbuild
rm -rf $localmirror

cd qemu-local-build
rm -rf *debuginfo*
createrepo .
cd ..

yum install -y qemu-img qemu-kvm libvirt virt-install lftp httpd fence-virtd-libvirt fence-virtd-tcp postgresql ansible cloud-utils cloud-utils-growpart

## setup simengine
# setup Neo4j repo
rpm --import https://debian.neo4j.com/neotechnology.gpg.key
cat <<EOF>  /etc/yum.repos.d/neo4j.repo
[neo4j]
name=Neo4j Yum Repo
baseurl=http://yum.neo4j.com/stable
enabled=1
gpgcheck=1
EOF
neover=$(yum search --showduplicates neo4j |grep neo4j-3 | sed -e 's#neo4j-##g' -e 's#-1.noarch.*##g' | sort -V | tail -n 1)
yum install -y neo4j-$neover
systemctl stop neo4j
systemctl enable neo4j
systemctl start neo4j

dnf -y module remove --all nodejs:10
dnf -y module reset nodejs
dnf -y module switch-to nodejs:12

# build Simengine - model is created after libvirt is configured
rm -rf simengine rpmbuild
git clone https://github.com/Seneca-CDOT/simengine.git
cd simengine/rpm/specfiles
./buildall
cd -
rm -f $BUILDDIR/storcli64
cp simengine/storage-emulation-tests/guest/storcli64 $BUILDDIR/
sed -i -e 's#env python#python3#g' $BUILDDIR/storcli64
yum install -y rpmbuild/RPMS/*/*.rpm
rm -rf simengine rpmbuild

systemctl enable simengine-core

## VIRT SETUP

# enable nested virt
if [ ! -f /etc/modprobe.d/netsted_virt.conf ] && [ "$(cat /sys/module/kvm_intel/parameters/nested)" = 0 ]; then
 systemctl stop libvirtd
 rmmod kvm-intel
 echo 'options kvm-intel nested=y' > /etc/modprobe.d/netsted_virt.conf
 modprobe kvm-intel
fi
if [ "$(cat /sys/module/kvm_intel/parameters/nested)" = 0 ]; then
 echo "WARNING!!! FAILED TO ENABLE NESTED VIRTUALIZATION!"
fi

# setup networking
systemctl start libvirtd
systemctl enable libvirtd
if [ -n "$(virsh net-list --all --name | grep default)" ]; then
 virsh net-destroy default
 virsh net-undefine default
fi

tmpfile=$(mktemp)
macbase=0
ifnbase=122
for i in ifn1 ifn2 bcn1 bcn2 sn1 sn2; do
 if [ -z "$(virsh net-list --all --name | grep ${i}_bridge1)" ]; then
  echo "Creating libvirt network interface ${i}_bridge1"
  uuid=$(uuidgen)
  cat > $tmpfile << EOF
<network>
 <name>${i}_bridge1</name>
 <uuid>${uuid}</uuid>
 <bridge name='${i}_bridge1' stp='on' delay='0'/>
 <domain name='${i}_bridge1'/>
 <mac address='52:54:${macbase}:e1:ac:a2'/>
EOF
  case ${i} in
   ifn*)
    cat >> $tmpfile << EOF
 <forward mode='nat'/>
 <ip address='192.168.$ifnbase.1' netmask='255.255.255.0'>
  <dhcp>
   <range start='192.168.$ifnbase.128' end='192.168.$ifnbase.254'/>
  </dhcp>
 </ip>
EOF
   ;;
   bcn1)
    cat >> $tmpfile << EOF
 <ip address='10.201.2.1' netmask='255.255.0.0'/>
 <ip address='10.201.2.2' netmask='255.255.0.0'/>
 <ip address='10.201.3.1' netmask='255.255.0.0'/>
 <ip address='10.201.3.2' netmask='255.255.0.0'/>
 <ip address='10.201.3.3' netmask='255.255.0.0'/>
 <ip address='10.201.11.1' netmask='255.255.0.0'/>
 <ip address='10.201.11.2' netmask='255.255.0.0'/>
 <ip address='10.201.11.3' netmask='255.255.0.0'/>
EOF
   ;;
  esac
  echo "</network>" >> $tmpfile
  virsh net-define $tmpfile
  virsh net-autostart ${i}_bridge1
  virsh net-start ${i}_bridge1
 fi
 macbase=$((macbase + 1))
 ifnbase=$((ifnbase + 100))
done
rm -f $tmpfile

for i in public libvirt; do
 for x in http https; do
  firewall-cmd --zone=$i --add-service=$x
  firewall-cmd --zone=$i --permanent --add-service=$x
 done
done
firewall-cmd --zone=libvirt --add-port=1229/tcp
firewall-cmd --zone=libvirt --permanent --add-port=1229/tcp
# required by simengine dashboard websocket
firewall-cmd --zone=public --add-port=8000/tcp
firewall-cmd --zone=public --permanent --add-port=8000/tcp
# required by simengine to access UPS/PDU and BMCs
firewall-cmd --zone=libvirt --add-port=161/udp
firewall-cmd --zone=libvirt --permanent --add-port=161/udp
firewall-cmd --zone=libvirt --add-port=623/udp
firewall-cmd --zone=libvirt --permanent --add-port=623/udp
firewall-cmd --reload

systemctl enable httpd
systemctl stop httpd
systemctl start httpd

if ! grep -q ifn1 /etc/fence_virt.conf; then
 sed -i \
  -e 's#virbr0#ifn1_bridge1#g' \
  -e 's#multicast#tcp#g' \
  -e 's#225.0.0.12#192.168.122.1#g' \
  /etc/fence_virt.conf
fi

if [ ! -f /etc/cluster/fence_xvm.key ]; then
 mkdir -p /etc/cluster/
 dd if=/dev/zero of=/etc/cluster/fence_xvm.key bs=4096 count=1
fi

systemctl start fence_virtd
systemctl enable fence_virtd
